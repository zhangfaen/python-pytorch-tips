{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5456079c",
   "metadata": {},
   "source": [
    "### **Python 对象 ID 的同一性问题：一个由内存复用引发的案例研究**\n",
    "**摘要**：本文探讨了一个在 Python 中不常见的现象：两个不同类型的对象在特定执行顺序下会展现出相同的 `id()` 值。通过使用 PyTorch 作为案例，我们证明了该现象源于 CPython 解释器的内存复用机制，并通过追溯 PyTorch 源码，揭示了其属性访问返回临时“包装器”对象的底层实现。\n",
    "\n",
    "## **1. 问题的提出**\n",
    "\n",
    "在 Python 中，`id()` 函数返回对象的唯一标识符，通常是其在内存中的地址。一个普遍的认知是，不同的对象拥有不同的 `id`。然而，在与某些扩展库（如 PyTorch）交互时，可能会观察到与此认知相悖的结果。\n",
    "\n",
    "**案例一：现象观察 (`observe_phenomenon.py`)**\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# 初始化两个张量并执行不同操作\n",
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "y1 = 2 / x1\n",
    "\n",
    "x2 = torch.tensor(3.0, requires_grad=True)\n",
    "y2 = x2 ** 3\n",
    "\n",
    "print(f\"y1.grad_fn type: {type(y1.grad_fn)}\")\n",
    "print(f\"y2.grad_fn type: {type(y2.grad_fn)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 顺序获取并比较 grad_fn 对象的 id\n",
    "id1 = id(y1.grad_fn)\n",
    "id2 = id(y2.grad_fn)\n",
    "\n",
    "print(f\"ID of y1.grad_fn: {id1}\")\n",
    "print(f\"ID of y2.grad_fn: {id2}\")\n",
    "print(f\"id1 == id2: {id1 == id2}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 使用 is 运算符进行身份比较\n",
    "print(f\"y1.grad_fn is y2.grad_fn: {y1.grad_fn is y2.grad_fn}\")\n",
    "```\n",
    "\n",
    "**运行输出：**\n",
    "```\n",
    "y1.grad_fn type: <class 'MulBackward0'>\n",
    "y2.grad_fn type: <class 'PowBackward0'>\n",
    "----------------------------------------\n",
    "ID of y1.grad_fn: 4426537744\n",
    "ID of y2.grad_fn: 4426537744\n",
    "id1 == id2: True\n",
    "----------------------------------------\n",
    "y1.grad_fn is y2.grad_fn: False\n",
    "```\n",
    "输出清晰地显示，`y1.grad_fn` 和 `y2.grad_fn` 是不同类型的对象，且 `is` 运算也确认为非同一对象，但它们的 `id()` 返回值却完全相同。这背后的机制是什么？\n",
    "\n",
    "## **2. 根源探究：临时对象与内存复用**\n",
    "\n",
    "此现象的根本原因有两个层面：\n",
    "\n",
    "1.  **CPython 的内存管理策略**：Python 对象的 `id` 仅在其**生命周期 (Lifetime)** 内保证唯一。当一个对象的引用计数归零后，其内存可被回收。为优化性能，CPython 倾向于将刚被释放的内存块**复用 (Reuse)** 于新创建的对象。\n",
    "2.  **PyTorch 的 C++/Python 接口实现**：`.grad_fn` 并非一个普通的 Python 属性。对它的每次访问都会触发 PyTorch 的 C++ 后端**动态创建一个新**的 Python 对象，作为底层 C++ 梯度节点的“包装器”(Wrapper)。\n",
    "\n",
    "结合这两点，案例一的执行流程得以解释：\n",
    "*   `id(y1.grad_fn)` 调用触发 PyTorch 创建一个临时的 `MulBackward0` Python 对象。`id()` 获取其地址后，该对象因无引用而被立即销毁，内存被释放。\n",
    "*   紧接着，`id(y2.grad_fn)` 调用再次触发 PyTorch 创建一个临时的 `PowBackward0` 对象。此时，CPython 的内存分配器极有可能复用刚刚被释放的内存地址。\n",
    "\n",
    "## **3. 实验验证：延长对象生命周期**\n",
    "\n",
    "根据以上分析，如果我们阻止第一个临时对象被销毁，内存复用现象就应该会消失。我们可以通过创建一个持久引用来实现这一点。\n",
    "\n",
    "**案例二：通过持久化引用进行验证 (`reveal_truth.py`)**\n",
    "```python\n",
    "import torch\n",
    "\n",
    "# 初始化与案例一相同\n",
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "y1 = 2 / x1\n",
    "x2 = torch.tensor(3.0, requires_grad=True)\n",
    "y2 = x2 ** 3\n",
    "\n",
    "print(f\"y1.grad_fn type: {type(y1.grad_fn)}\")\n",
    "print(f\"y2.grad_fn type: {type(y2.grad_fn)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 创建一个持久引用，延长 y1.grad_fn 的生命周期\n",
    "grad_fn_1 = y1.grad_fn \n",
    "\n",
    "id1 = id(grad_fn_1)\n",
    "id2 = id(y2.grad_fn)\n",
    "\n",
    "print(f\"ID of persistent y1.grad_fn: {id1}\")\n",
    "print(f\"ID of y2.grad_fn: {id2}\")\n",
    "print(f\"id1 == id2: {id1 == id2}\")\n",
    "\n",
    "```\n",
    "\n",
    "**运行输出：**\n",
    "```\n",
    "y1.grad_fn type: <class 'MulBackward0'>\n",
    "y2.grad_fn type: <class 'PowBackward0'>\n",
    "----------------------------------------\n",
    "ID of persistent y1.grad_fn: 4366609232\n",
    "ID of y2.grad_fn: 4366609296\n",
    "id1 == id2: False\n",
    "```\n",
    "实验结果证实了我们的分析。当 `y1.grad_fn` 返回的对象被变量 `grad_fn_1` 引用后，其生命周期得以延长，内存无法被复用。因此，`y2.grad_fn` 返回的新对象必须被分配到一块不同的内存地址。\n",
    "\n",
    "## **4. PyTorch 源码佐证**\n",
    "\n",
    "在 PyTorch 源码 `torch/csrc/autograd/python_variable.cpp` 中，`.grad_fn` 属性被定义为一个 `getter` 函数 `THPVariable_get_grad_fn`。\n",
    "\n",
    "该 C++ 函数的核心逻辑是调用 `torch::autograd::python::PyNode_New()`，此函数会为底层的 C++ 梯度节点**分配新内存并创建一个全新的 Python 对象**。这个实现从根本上决定了每次对 `.grad_fn` 的访问都会返回一个独立的、生命周期可能极短的临时对象，从而为内存复用创造了条件。\n",
    "\n",
    "## **5. 结论**\n",
    "\n",
    "1.  Python 对象的 `id` 唯一性是限定在其生命周期内的。\n",
    "2.  CPython 的内存复用机制是导致已销毁对象的 `id` 被新对象重用的直接原因。\n",
    "3.  在由 C++ 等底层语言实现的库中，属性访问动态创建临时 Python 包装器是一种常见模式。必须意识到这些对象的短暂性。\n",
    "4.  判断两个变量是否指向同一对象的唯一可靠方法是使用 `is` 运算符，而非依赖 `id()` 的比较。\n",
    "\n",
    "理解这一底层机制有助于开发者编写更健壮的代码，并能准确诊断在特定场景下出现的异常行为。\n",
    "\n",
    "## **6. 附录**\n",
    "若你未能复现上述现象，可以参考我的运行环境。\n",
    "```\n",
    "Operating System: Linux-6.8.0-60-generic-x86_64-with-glibc2.35\n",
    "Python Version:   3.12.11 (CPython)\n",
    "PyTorch Version:  2.8.0+cu128\n",
    "---------------------------\n",
    "CUDA Available:   True\n",
    "CUDA Version:     12.8\n",
    "cuDNN Version:    91002\n",
    "GPU Name:         NVIDIA A800 80GB PCIe\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35547ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1.grad_fn type: <class 'MulBackward0'>\n",
      "y2.grad_fn type: <class 'PowBackward0'>\n",
      "----------------------------------------\n",
      "ID of y1.grad_fn: 16650927136176\n",
      "ID of y2.grad_fn: 16650927136176\n",
      "id1 == id2: True\n",
      "----------------------------------------\n",
      "y1.grad_fn is y2.grad_fn: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 初始化两个张量并执行不同操作\n",
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "y1 = 2 / x1\n",
    "\n",
    "x2 = torch.tensor(3.0, requires_grad=True)\n",
    "y2 = x2 ** 3\n",
    "\n",
    "print(f\"y1.grad_fn type: {type(y1.grad_fn)}\")\n",
    "print(f\"y2.grad_fn type: {type(y2.grad_fn)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 顺序获取并比较 grad_fn 对象的 id\n",
    "id1 = id(y1.grad_fn)\n",
    "id2 = id(y2.grad_fn)\n",
    "\n",
    "print(f\"ID of y1.grad_fn: {id1}\")\n",
    "print(f\"ID of y2.grad_fn: {id2}\")\n",
    "print(f\"id1 == id2: {id1 == id2}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 使用 is 运算符进行身份比较\n",
    "print(f\"y1.grad_fn is y2.grad_fn: {y1.grad_fn is y2.grad_fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c34a959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1.grad_fn type: <class 'MulBackward0'>\n",
      "y2.grad_fn type: <class 'PowBackward0'>\n",
      "----------------------------------------\n",
      "ID of persistent y1.grad_fn: 16650925947440\n",
      "ID of y2.grad_fn: 16650926164576\n",
      "id1 == id2: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 初始化与案例一相同\n",
    "x1 = torch.tensor(2.0, requires_grad=True)\n",
    "y1 = 2 / x1\n",
    "x2 = torch.tensor(3.0, requires_grad=True)\n",
    "y2 = x2 ** 3\n",
    "\n",
    "print(f\"y1.grad_fn type: {type(y1.grad_fn)}\")\n",
    "print(f\"y2.grad_fn type: {type(y2.grad_fn)}\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# 创建一个持久引用，延长 y1.grad_fn 的生命周期\n",
    "grad_fn_1 = y1.grad_fn \n",
    "\n",
    "id1 = id(grad_fn_1)\n",
    "id2 = id(y2.grad_fn)\n",
    "\n",
    "print(f\"ID of persistent y1.grad_fn: {id1}\")\n",
    "print(f\"ID of y2.grad_fn: {id2}\")\n",
    "print(f\"id1 == id2: {id1 == id2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d297df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Environment Details ---\n",
      "Operating System: Linux-6.8.0-60-generic-x86_64-with-glibc2.35\n",
      "Python Version:   3.12.11 (CPython)\n",
      "PyTorch Version:  2.8.0+cu128\n",
      "---------------------------\n",
      "CUDA Available:   True\n",
      "CUDA Version:     12.8\n",
      "cuDNN Version:    91002\n",
      "GPU Name:         NVIDIA A800 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import platform\n",
    "import torch\n",
    "\n",
    "# 格式化打印环境信息\n",
    "print(\"--- Environment Details ---\")\n",
    "print(f\"Operating System: {platform.platform()}\")\n",
    "print(f\"Python Version:   {sys.version.split()[0]} ({platform.python_implementation()})\")\n",
    "print(f\"PyTorch Version:  {torch.__version__}\")\n",
    "print(\"---------------------------\")\n",
    "\n",
    "# 也可以查询 CUDA 相关信息（如果安装了GPU版本）\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Available:   True\")\n",
    "    print(f\"CUDA Version:     {torch.version.cuda}\")\n",
    "    print(f\"cuDNN Version:    {torch.backends.cudnn.version()}\")\n",
    "    print(f\"GPU Name:         {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA Available:   False\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gspo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
