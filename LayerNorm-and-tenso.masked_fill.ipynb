{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html\">LayerNorm</a>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<a href=\"https://pytorch.org/docs/stable/generated/torch.nn.LayerNorm.html\">LayerNorm</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 3])\n",
      "tensor([[[-1.2247e+00,  0.0000e+00,  1.2247e+00],\n",
      "         [-1.2247e+00,  1.1921e-07,  1.2247e+00],\n",
      "         [-1.2978e+00,  1.6222e-01,  1.1355e+00]]],\n",
      "       grad_fn=<NativeLayerNormBackward0>)\n",
      "tensor([-1.2247,  0.0000,  1.2247])\n",
      "tensor([-1.2247,  0.0000,  1.2247])\n",
      "tensor([-1.2978,  0.1622,  1.1355])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import normalize\n",
    "from typing import Tuple\n",
    "\n",
    "\n",
    "def my_layer_norm(\n",
    "    x: torch.Tensor, dim: Tuple[int], eps: float = 0.00001\n",
    ") -> torch.Tensor:\n",
    "    mean = torch.mean(x, dim=dim, keepdim=True)\n",
    "    var = torch.square(x - mean).mean(dim=dim, keepdim=True)\n",
    "    return (x - mean) / torch.sqrt(var + eps)\n",
    "\n",
    "\n",
    "batch, sentence_length, embedding_dim = 1, 3, 3\n",
    "embedding = torch.tensor(\n",
    "    [[[1.0, 2.0, 3.0],\n",
    "     [2.0, 3.0, 4.0],\n",
    "     [1.0, 4.0, 6.0]]])\n",
    "print(embedding.shape)\n",
    "layer_norm = nn.LayerNorm(3, elementwise_affine=True)\n",
    "output = layer_norm(embedding)\n",
    "print(output)\n",
    "\n",
    "print(my_layer_norm(torch.tensor([1.0, 2.0, 3.0]), 0))\n",
    "print(my_layer_norm(torch.tensor([2.0, 3.0, 4.0]), 0))\n",
    "print(my_layer_norm(torch.tensor([1.0, 4.0, 6.0]), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor(2.5000)\n",
      "tensor([[2., 3.]])\n",
      "tensor([[1.5000],\n",
      "        [3.5000]])\n",
      "tensor([2., 3.])\n",
      "tensor([1.5000, 3.5000])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "a = torch.Tensor([[1.0, 2.0], [3.0, 4.0]])\n",
    "print(a.shape)\n",
    "print(torch.mean(a))\n",
    "print(torch.mean(a, 0, True))\n",
    "print(torch.mean(a, 1, True))\n",
    "print(torch.mean(a, 0, False))\n",
    "print(torch.mean(a, 1, False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function mean in module torch:\n",
      "\n",
      "mean(...)\n",
      "    mean(input, *, dtype=None) -> Tensor\n",
      "    \n",
      "    Returns the mean value of all elements in the :attr:`input` tensor.\n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "    \n",
      "    Keyword args:\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "            is performed. This is useful for preventing data type overflows. Default: None.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(1, 3)\n",
      "        >>> a\n",
      "        tensor([[ 0.2294, -0.5481,  1.3288]])\n",
      "        >>> torch.mean(a)\n",
      "        tensor(0.3367)\n",
      "    \n",
      "    .. function:: mean(input, dim, keepdim=False, *, dtype=None, out=None) -> Tensor\n",
      "       :noindex:\n",
      "    \n",
      "    Returns the mean value of each row of the :attr:`input` tensor in the given\n",
      "    dimension :attr:`dim`. If :attr:`dim` is a list of dimensions,\n",
      "    reduce over all of them.\n",
      "    \n",
      "    \n",
      "    If :attr:`keepdim` is ``True``, the output tensor is of the same size\n",
      "    as :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\n",
      "    Otherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\n",
      "    output tensor having 1 (or ``len(dim)``) fewer dimension(s).\n",
      "    \n",
      "    \n",
      "    Args:\n",
      "        input (Tensor): the input tensor.\n",
      "        dim (int or tuple of ints): the dimension or dimensions to reduce.\n",
      "        keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n",
      "    \n",
      "    Keyword args:\n",
      "        dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n",
      "            If specified, the input tensor is casted to :attr:`dtype` before the operation\n",
      "            is performed. This is useful for preventing data type overflows. Default: None.\n",
      "        out (Tensor, optional): the output tensor.\n",
      "    \n",
      "    .. seealso::\n",
      "    \n",
      "        :func:`torch.nanmean` computes the mean value of `non-NaN` elements.\n",
      "    \n",
      "    Example::\n",
      "    \n",
      "        >>> a = torch.randn(4, 4)\n",
      "        >>> a\n",
      "        tensor([[-0.3841,  0.6320,  0.4254, -0.7384],\n",
      "                [-0.9644,  1.0131, -0.6549, -1.4279],\n",
      "                [-0.2951, -1.3350, -0.7694,  0.5600],\n",
      "                [ 1.0842, -0.9580,  0.3623,  0.2343]])\n",
      "        >>> torch.mean(a, 1)\n",
      "        tensor([-0.0163, -0.5085, -0.4599,  0.1807])\n",
      "        >>> torch.mean(a, 1, True)\n",
      "        tensor([[-0.0163],\n",
      "                [-0.5085],\n",
      "                [-0.4599],\n",
      "                [ 0.1807]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(torch.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 2, 2])\n",
      "tensor([[[[False,  True],\n",
      "          [ True, False]]]])\n",
      "before mask:\n",
      "tensor([[[[-0.4132, -0.2266],\n",
      "          [ 0.2604,  1.0856]],\n",
      "\n",
      "         [[-2.3782, -0.5554],\n",
      "          [ 0.6914, -0.2681]],\n",
      "\n",
      "         [[ 0.9550, -0.7643],\n",
      "          [-1.2810,  0.0563]]],\n",
      "\n",
      "\n",
      "        [[[-0.0229,  0.9606],\n",
      "          [-0.6099,  0.1671]],\n",
      "\n",
      "         [[-0.3016, -1.1551],\n",
      "          [ 1.0394,  0.8793]],\n",
      "\n",
      "         [[ 0.2370, -0.2745],\n",
      "          [-0.8201, -2.4180]]]])\n",
      "after maks:\n",
      "tensor([[[[-0.4132,    -inf],\n",
      "          [   -inf,  1.0856]],\n",
      "\n",
      "         [[-2.3782,    -inf],\n",
      "          [   -inf, -0.2681]],\n",
      "\n",
      "         [[ 0.9550,    -inf],\n",
      "          [   -inf,  0.0563]]],\n",
      "\n",
      "\n",
      "        [[[-0.0229,    -inf],\n",
      "          [   -inf,  0.1671]],\n",
      "\n",
      "         [[-0.3016,    -inf],\n",
      "          [   -inf,  0.8793]],\n",
      "\n",
      "         [[ 0.2370,    -inf],\n",
      "          [   -inf, -2.4180]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ts = torch.randn((2,3,2,2), dtype=torch.float)\n",
    "mask = torch.tensor([[\n",
    "    [[1, 0],\n",
    "    [0, 1]],\n",
    "]])\n",
    "print(mask.shape)\n",
    "print(mask == 0)\n",
    "print(\"before mask:\")\n",
    "print(ts)\n",
    "ts = ts.masked_fill(mask==0, float('-inf'))\n",
    "print(\"after maks:\")\n",
    "print(ts)\n",
    "\n",
    "# att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
